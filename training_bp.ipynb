{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e27b176-d698-4e04-8b27-78f53d0265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinbob/PycharmProjects/tensorflow-sample/env/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 55ms/step - accuracy: 0.2212 - loss: 2.4637 - val_accuracy: 0.7574 - val_loss: 0.6574 - learning_rate: 0.0010\n",
      "Epoch 2/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - accuracy: 0.6414 - loss: 1.0683 - val_accuracy: 0.8720 - val_loss: 0.3988 - learning_rate: 0.0010\n",
      "Epoch 3/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.7357 - loss: 0.8397 - val_accuracy: 0.9220 - val_loss: 0.3034 - learning_rate: 0.0010\n",
      "Epoch 4/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - accuracy: 0.7881 - loss: 0.7267 - val_accuracy: 0.9506 - val_loss: 0.1900 - learning_rate: 0.0010\n",
      "Epoch 5/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.8216 - loss: 0.6519 - val_accuracy: 0.9542 - val_loss: 0.1693 - learning_rate: 0.0010\n",
      "Epoch 6/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.8495 - loss: 0.5741 - val_accuracy: 0.9555 - val_loss: 0.1600 - learning_rate: 0.0010\n",
      "Epoch 7/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.8608 - loss: 0.5407 - val_accuracy: 0.9624 - val_loss: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 8/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.8674 - loss: 0.5166 - val_accuracy: 0.9567 - val_loss: 0.1555 - learning_rate: 0.0010\n",
      "Epoch 9/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.8743 - loss: 0.5004 - val_accuracy: 0.9626 - val_loss: 0.1365 - learning_rate: 0.0010\n",
      "Epoch 10/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.8813 - loss: 0.4689 - val_accuracy: 0.9632 - val_loss: 0.1341 - learning_rate: 0.0010\n",
      "Epoch 11/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - accuracy: 0.8837 - loss: 0.4521 - val_accuracy: 0.9665 - val_loss: 0.1201 - learning_rate: 0.0010\n",
      "Epoch 12/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.8899 - loss: 0.4357 - val_accuracy: 0.9719 - val_loss: 0.1037 - learning_rate: 0.0010\n",
      "Epoch 13/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.8950 - loss: 0.4245 - val_accuracy: 0.9719 - val_loss: 0.1074 - learning_rate: 0.0010\n",
      "Epoch 14/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - accuracy: 0.8981 - loss: 0.4137 - val_accuracy: 0.9646 - val_loss: 0.1292 - learning_rate: 0.0010\n",
      "Epoch 15/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9007 - loss: 0.4092 - val_accuracy: 0.9759 - val_loss: 0.0945 - learning_rate: 0.0010\n",
      "Epoch 16/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - accuracy: 0.9006 - loss: 0.3986 - val_accuracy: 0.9751 - val_loss: 0.0897 - learning_rate: 0.0010\n",
      "Epoch 17/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.9048 - loss: 0.3873 - val_accuracy: 0.9757 - val_loss: 0.0836 - learning_rate: 0.0010\n",
      "Epoch 18/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.9081 - loss: 0.3734 - val_accuracy: 0.9753 - val_loss: 0.0873 - learning_rate: 0.0010\n",
      "Epoch 19/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - accuracy: 0.9075 - loss: 0.3762 - val_accuracy: 0.9757 - val_loss: 0.0859 - learning_rate: 0.0010\n",
      "Epoch 20/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - accuracy: 0.9081 - loss: 0.3700 - val_accuracy: 0.9782 - val_loss: 0.0803 - learning_rate: 0.0010\n",
      "Epoch 21/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9090 - loss: 0.3695 - val_accuracy: 0.9800 - val_loss: 0.0751 - learning_rate: 0.0010\n",
      "Epoch 22/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.9118 - loss: 0.3604 - val_accuracy: 0.9784 - val_loss: 0.0763 - learning_rate: 0.0010\n",
      "Epoch 23/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9118 - loss: 0.3631 - val_accuracy: 0.9789 - val_loss: 0.0728 - learning_rate: 0.0010\n",
      "Epoch 24/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9152 - loss: 0.3503 - val_accuracy: 0.9793 - val_loss: 0.0761 - learning_rate: 0.0010\n",
      "Epoch 25/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9152 - loss: 0.3468 - val_accuracy: 0.9789 - val_loss: 0.0773 - learning_rate: 0.0010\n",
      "Epoch 26/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9166 - loss: 0.3425 - val_accuracy: 0.9790 - val_loss: 0.0774 - learning_rate: 0.0010\n",
      "Epoch 27/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.9230 - loss: 0.3197 - val_accuracy: 0.9834 - val_loss: 0.0615 - learning_rate: 5.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9251 - loss: 0.3136 - val_accuracy: 0.9835 - val_loss: 0.0630 - learning_rate: 5.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - accuracy: 0.9250 - loss: 0.3098 - val_accuracy: 0.9826 - val_loss: 0.0646 - learning_rate: 5.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 58ms/step - accuracy: 0.9267 - loss: 0.3031 - val_accuracy: 0.9818 - val_loss: 0.0659 - learning_rate: 5.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9278 - loss: 0.3087 - val_accuracy: 0.9840 - val_loss: 0.0599 - learning_rate: 2.5000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.9327 - loss: 0.2864 - val_accuracy: 0.9845 - val_loss: 0.0578 - learning_rate: 2.5000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9319 - loss: 0.2926 - val_accuracy: 0.9844 - val_loss: 0.0584 - learning_rate: 2.5000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - accuracy: 0.9319 - loss: 0.2850 - val_accuracy: 0.9841 - val_loss: 0.0564 - learning_rate: 2.5000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - accuracy: 0.9323 - loss: 0.2796 - val_accuracy: 0.9839 - val_loss: 0.0571 - learning_rate: 2.5000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9334 - loss: 0.2794 - val_accuracy: 0.9834 - val_loss: 0.0602 - learning_rate: 2.5000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 59ms/step - accuracy: 0.9356 - loss: 0.2810 - val_accuracy: 0.9846 - val_loss: 0.0565 - learning_rate: 2.5000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9350 - loss: 0.2811 - val_accuracy: 0.9847 - val_loss: 0.0540 - learning_rate: 1.2500e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9353 - loss: 0.2697 - val_accuracy: 0.9857 - val_loss: 0.0537 - learning_rate: 1.2500e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 51ms/step - accuracy: 0.9359 - loss: 0.2726 - val_accuracy: 0.9861 - val_loss: 0.0517 - learning_rate: 1.2500e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 50ms/step - accuracy: 0.9369 - loss: 0.2684 - val_accuracy: 0.9859 - val_loss: 0.0521 - learning_rate: 1.2500e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9386 - loss: 0.2656 - val_accuracy: 0.9863 - val_loss: 0.0530 - learning_rate: 1.2500e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 51ms/step - accuracy: 0.9371 - loss: 0.2665 - val_accuracy: 0.9863 - val_loss: 0.0504 - learning_rate: 1.2500e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9381 - loss: 0.2658 - val_accuracy: 0.9865 - val_loss: 0.0504 - learning_rate: 1.2500e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9388 - loss: 0.2591 - val_accuracy: 0.9860 - val_loss: 0.0517 - learning_rate: 1.2500e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9387 - loss: 0.2612 - val_accuracy: 0.9865 - val_loss: 0.0511 - learning_rate: 1.2500e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9389 - loss: 0.2628 - val_accuracy: 0.9864 - val_loss: 0.0510 - learning_rate: 6.2500e-05\n",
      "Epoch 48/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9369 - loss: 0.2639 - val_accuracy: 0.9861 - val_loss: 0.0510 - learning_rate: 6.2500e-05\n",
      "Epoch 49/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9368 - loss: 0.2724 - val_accuracy: 0.9857 - val_loss: 0.0498 - learning_rate: 6.2500e-05\n",
      "Epoch 50/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9396 - loss: 0.2529 - val_accuracy: 0.9864 - val_loss: 0.0497 - learning_rate: 6.2500e-05\n",
      "Epoch 51/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9396 - loss: 0.2609 - val_accuracy: 0.9866 - val_loss: 0.0495 - learning_rate: 6.2500e-05\n",
      "Epoch 52/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 51ms/step - accuracy: 0.9405 - loss: 0.2550 - val_accuracy: 0.9862 - val_loss: 0.0500 - learning_rate: 6.2500e-05\n",
      "Epoch 53/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 50ms/step - accuracy: 0.9386 - loss: 0.2581 - val_accuracy: 0.9857 - val_loss: 0.0504 - learning_rate: 6.2500e-05\n",
      "Epoch 54/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9379 - loss: 0.2660 - val_accuracy: 0.9863 - val_loss: 0.0501 - learning_rate: 6.2500e-05\n",
      "Epoch 55/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 50ms/step - accuracy: 0.9402 - loss: 0.2563 - val_accuracy: 0.9864 - val_loss: 0.0498 - learning_rate: 3.1250e-05\n",
      "Epoch 56/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 50ms/step - accuracy: 0.9399 - loss: 0.2608 - val_accuracy: 0.9866 - val_loss: 0.0496 - learning_rate: 3.1250e-05\n",
      "Epoch 57/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 50ms/step - accuracy: 0.9406 - loss: 0.2477 - val_accuracy: 0.9866 - val_loss: 0.0492 - learning_rate: 3.1250e-05\n",
      "Epoch 58/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 50ms/step - accuracy: 0.9395 - loss: 0.2542 - val_accuracy: 0.9863 - val_loss: 0.0487 - learning_rate: 3.1250e-05\n",
      "Epoch 59/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9392 - loss: 0.2615 - val_accuracy: 0.9867 - val_loss: 0.0495 - learning_rate: 3.1250e-05\n",
      "Epoch 60/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9393 - loss: 0.2547 - val_accuracy: 0.9866 - val_loss: 0.0490 - learning_rate: 3.1250e-05\n",
      "Epoch 61/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - accuracy: 0.9388 - loss: 0.2620 - val_accuracy: 0.9871 - val_loss: 0.0486 - learning_rate: 3.1250e-05\n",
      "Epoch 62/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9411 - loss: 0.2499 - val_accuracy: 0.9867 - val_loss: 0.0488 - learning_rate: 1.5625e-05\n",
      "Epoch 63/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9401 - loss: 0.2573 - val_accuracy: 0.9866 - val_loss: 0.0483 - learning_rate: 1.5625e-05\n",
      "Epoch 64/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9417 - loss: 0.2537 - val_accuracy: 0.9871 - val_loss: 0.0484 - learning_rate: 1.5625e-05\n",
      "Epoch 65/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - accuracy: 0.9394 - loss: 0.2583 - val_accuracy: 0.9869 - val_loss: 0.0487 - learning_rate: 1.5625e-05\n",
      "Epoch 66/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - accuracy: 0.9381 - loss: 0.2627 - val_accuracy: 0.9871 - val_loss: 0.0480 - learning_rate: 1.5625e-05\n",
      "Epoch 67/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 56ms/step - accuracy: 0.9423 - loss: 0.2482 - val_accuracy: 0.9868 - val_loss: 0.0479 - learning_rate: 1.5625e-05\n",
      "Epoch 68/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9407 - loss: 0.2512 - val_accuracy: 0.9872 - val_loss: 0.0477 - learning_rate: 1.5625e-05\n",
      "Epoch 69/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9407 - loss: 0.2508 - val_accuracy: 0.9872 - val_loss: 0.0481 - learning_rate: 1.5625e-05\n",
      "Epoch 70/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 57ms/step - accuracy: 0.9423 - loss: 0.2535 - val_accuracy: 0.9871 - val_loss: 0.0475 - learning_rate: 1.5625e-05\n",
      "Epoch 71/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - accuracy: 0.9425 - loss: 0.2436 - val_accuracy: 0.9869 - val_loss: 0.0479 - learning_rate: 1.5625e-05\n",
      "Epoch 72/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 55ms/step - accuracy: 0.9403 - loss: 0.2564 - val_accuracy: 0.9871 - val_loss: 0.0472 - learning_rate: 1.5625e-05\n",
      "Epoch 73/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9417 - loss: 0.2497 - val_accuracy: 0.9871 - val_loss: 0.0484 - learning_rate: 1.5625e-05\n",
      "Epoch 74/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 58ms/step - accuracy: 0.9416 - loss: 0.2505 - val_accuracy: 0.9868 - val_loss: 0.0483 - learning_rate: 1.5625e-05\n",
      "Epoch 75/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9414 - loss: 0.2491 - val_accuracy: 0.9867 - val_loss: 0.0480 - learning_rate: 1.5625e-05\n",
      "Epoch 76/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9414 - loss: 0.2555 - val_accuracy: 0.9869 - val_loss: 0.0476 - learning_rate: 1.0000e-05\n",
      "Epoch 77/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 54ms/step - accuracy: 0.9415 - loss: 0.2517 - val_accuracy: 0.9869 - val_loss: 0.0479 - learning_rate: 1.0000e-05\n",
      "Epoch 78/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 53ms/step - accuracy: 0.9425 - loss: 0.2443 - val_accuracy: 0.9870 - val_loss: 0.0480 - learning_rate: 1.0000e-05\n",
      "Epoch 79/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 52ms/step - accuracy: 0.9404 - loss: 0.2518 - val_accuracy: 0.9871 - val_loss: 0.0481 - learning_rate: 1.0000e-05\n",
      "Epoch 80/300\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 52ms/step - accuracy: 0.9402 - loss: 0.2553 - val_accuracy: 0.9872 - val_loss: 0.0476 - learning_rate: 1.0000e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0550\n",
      "Test Loss: 0.0472, Test Accuracy: 0.9871\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Input, LeakyReLU\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据预处理\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)  # 保持原始图像形状并添加通道维度\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 数据增强\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 构建改进后的BP神经网络模型\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(28, 28, 1)),  # 使用Input层指定输入形状\n",
    "        Flatten(),  # 展平图像\n",
    "\n",
    "        Dense(2048),  # 输入层 -> 隐藏层 1\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(1024),  # 隐藏层 2\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(512),  # 隐藏层 3\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(256),  # 隐藏层 4\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(128),  # 隐藏层 5\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(64),  # 隐藏层 6\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(32),  # 隐藏层 7\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(10, activation=\"softmax\"),  # 输出层\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),  # 使用RMSprop优化器\n",
    "    loss=\"categorical_crossentropy\",  # 多分类交叉熵损失\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 回调函数\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=3, min_lr=0.00001\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=8, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=128),  # 调整批量大小\n",
    "    epochs=300,  # 增加训练轮数\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# 测试模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "model.save(\"mnist_model_bp_v1.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
