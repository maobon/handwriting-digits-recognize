{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e27b176-d698-4e04-8b27-78f53d0265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 34ms/step - accuracy: 0.4063 - loss: 1.8082 - val_accuracy: 0.7779 - val_loss: 0.8089 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 35ms/step - accuracy: 0.4528 - loss: 1.6070 - val_accuracy: 0.7388 - val_loss: 0.9167 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4442 - loss: 1.6247 - val_accuracy: 0.7357 - val_loss: 0.9401 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4371 - loss: 1.6414 - val_accuracy: 0.7302 - val_loss: 0.9846 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 34ms/step - accuracy: 0.4363 - loss: 1.6484 - val_accuracy: 0.7056 - val_loss: 1.0222 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 33ms/step - accuracy: 0.4379 - loss: 1.6342 - val_accuracy: 0.7100 - val_loss: 1.0311 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 35ms/step - accuracy: 0.4312 - loss: 1.6468 - val_accuracy: 0.7013 - val_loss: 1.0535 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 35ms/step - accuracy: 0.4264 - loss: 1.6584 - val_accuracy: 0.6935 - val_loss: 1.0727 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4281 - loss: 1.6656\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 35ms/step - accuracy: 0.4281 - loss: 1.6656 - val_accuracy: 0.6754 - val_loss: 1.0883 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 35ms/step - accuracy: 0.4269 - loss: 1.6630 - val_accuracy: 0.6905 - val_loss: 1.0938 - learning_rate: 5.0000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4228 - loss: 1.6731 - val_accuracy: 0.6928 - val_loss: 1.0843 - learning_rate: 5.0000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4279 - loss: 1.6693 - val_accuracy: 0.6886 - val_loss: 1.0916 - learning_rate: 5.0000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4300 - loss: 1.6626 - val_accuracy: 0.6920 - val_loss: 1.0949 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4307 - loss: 1.6632 - val_accuracy: 0.6834 - val_loss: 1.0909 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4321 - loss: 1.6610 - val_accuracy: 0.6828 - val_loss: 1.0942 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4350 - loss: 1.6474 - val_accuracy: 0.6809 - val_loss: 1.0832 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m1874/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4341 - loss: 1.6498\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4341 - loss: 1.6498 - val_accuracy: 0.6841 - val_loss: 1.0887 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4341 - loss: 1.6426 - val_accuracy: 0.6884 - val_loss: 1.0798 - learning_rate: 2.5000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4367 - loss: 1.6427 - val_accuracy: 0.6866 - val_loss: 1.0863 - learning_rate: 2.5000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.4333 - loss: 1.6597 - val_accuracy: 0.6839 - val_loss: 1.0853 - learning_rate: 2.5000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m987s\u001b[0m 527ms/step - accuracy: 0.4289 - loss: 1.6564 - val_accuracy: 0.6871 - val_loss: 1.0802 - learning_rate: 2.5000e-04\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7455 - loss: 0.8710\n",
      "Test Loss: 0.8089, Test Accuracy: 0.7779\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据预处理\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)  # 保持原始图像形状并添加通道维度\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 数据增强\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 构建BP神经网络模型\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(28, 28, 1)),  # 使用Input层指定输入形状\n",
    "        Flatten(),  # 展平图像\n",
    "\n",
    "        Dense(512, activation=\"relu\"),  # 输入层 -> 隐藏层 1\n",
    "        BatchNormalization(),  # 批量归一化\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Dense(256, activation=\"relu\"),  # 隐藏层 2\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(128, activation=\"relu\"),  # 隐藏层 3\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(64, activation=\"relu\"),  # 隐藏层 4\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(10, activation=\"softmax\"),  # 输出层\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # 降低学习率\n",
    "    loss=\"categorical_crossentropy\",  # 多分类交叉熵损失\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 回调函数\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=20, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=32),\n",
    "    epochs=200,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# 测试模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "model.save(\"mnist_model_bp_v1.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
