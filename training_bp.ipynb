{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e27b176-d698-4e04-8b27-78f53d0265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 15:30:57.861032: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468/469 [============================>.] - ETA: 0s - loss: 2.4554 - accuracy: 0.1445"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 15:31:12.907518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 18s 34ms/step - loss: 2.4548 - accuracy: 0.1445 - val_loss: 2.1064 - val_accuracy: 0.2430 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 2.1464 - accuracy: 0.1998 - val_loss: 1.9107 - val_accuracy: 0.2560 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 2.0569 - accuracy: 0.2335 - val_loss: 1.7987 - val_accuracy: 0.3258 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 1.9889 - accuracy: 0.2628 - val_loss: 1.6944 - val_accuracy: 0.3724 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 1.9012 - accuracy: 0.3062 - val_loss: 1.4022 - val_accuracy: 0.4915 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.7946 - accuracy: 0.3596 - val_loss: 1.2415 - val_accuracy: 0.5904 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.7199 - accuracy: 0.3955 - val_loss: 1.0945 - val_accuracy: 0.6655 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.6522 - accuracy: 0.4229 - val_loss: 1.0298 - val_accuracy: 0.6335 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.5886 - accuracy: 0.4499 - val_loss: 0.9253 - val_accuracy: 0.7007 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.5505 - accuracy: 0.4621 - val_loss: 0.8651 - val_accuracy: 0.7252 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.5085 - accuracy: 0.4784 - val_loss: 0.9117 - val_accuracy: 0.6488 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.4786 - accuracy: 0.4899 - val_loss: 0.8260 - val_accuracy: 0.7064 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 1.4382 - accuracy: 0.5034 - val_loss: 0.7212 - val_accuracy: 0.7603 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.4203 - accuracy: 0.5117 - val_loss: 0.6813 - val_accuracy: 0.7734 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 1.3898 - accuracy: 0.5220 - val_loss: 0.6446 - val_accuracy: 0.7827 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 1.3707 - accuracy: 0.5288 - val_loss: 0.6140 - val_accuracy: 0.8020 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.3451 - accuracy: 0.5414 - val_loss: 0.6163 - val_accuracy: 0.7920 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.3283 - accuracy: 0.5462 - val_loss: 0.6286 - val_accuracy: 0.7920 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 1.3140 - accuracy: 0.5566 - val_loss: 0.5599 - val_accuracy: 0.8351 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.2933 - accuracy: 0.5643 - val_loss: 0.5305 - val_accuracy: 0.8404 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.2651 - accuracy: 0.5758 - val_loss: 0.4904 - val_accuracy: 0.8597 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.2664 - accuracy: 0.5794 - val_loss: 0.4849 - val_accuracy: 0.8639 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.2412 - accuracy: 0.5867 - val_loss: 0.4850 - val_accuracy: 0.8673 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.2282 - accuracy: 0.5941 - val_loss: 0.4411 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.2130 - accuracy: 0.5994 - val_loss: 0.3997 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.1983 - accuracy: 0.6065 - val_loss: 0.3709 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.1776 - accuracy: 0.6143 - val_loss: 0.3509 - val_accuracy: 0.9033 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.1662 - accuracy: 0.6194 - val_loss: 0.3853 - val_accuracy: 0.8938 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.1540 - accuracy: 0.6222 - val_loss: 0.3364 - val_accuracy: 0.9106 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.1442 - accuracy: 0.6262 - val_loss: 0.3145 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.1338 - accuracy: 0.6292 - val_loss: 0.3000 - val_accuracy: 0.9153 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.1154 - accuracy: 0.6353 - val_loss: 0.3221 - val_accuracy: 0.9049 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.1062 - accuracy: 0.6403 - val_loss: 0.2855 - val_accuracy: 0.9185 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 1.0990 - accuracy: 0.6428 - val_loss: 0.3136 - val_accuracy: 0.9128 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.0872 - accuracy: 0.6474 - val_loss: 0.2935 - val_accuracy: 0.9179 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.0862 - accuracy: 0.6466 - val_loss: 0.2852 - val_accuracy: 0.9176 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.0707 - accuracy: 0.6520 - val_loss: 0.2477 - val_accuracy: 0.9295 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.0577 - accuracy: 0.6561 - val_loss: 0.2586 - val_accuracy: 0.9273 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.0503 - accuracy: 0.6569 - val_loss: 0.2632 - val_accuracy: 0.9260 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.0479 - accuracy: 0.6590 - val_loss: 0.2679 - val_accuracy: 0.9218 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 1.0035 - accuracy: 0.6740 - val_loss: 0.2334 - val_accuracy: 0.9361 - lr: 5.0000e-04\n",
      "Epoch 42/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9906 - accuracy: 0.6787 - val_loss: 0.2301 - val_accuracy: 0.9342 - lr: 5.0000e-04\n",
      "Epoch 43/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9691 - accuracy: 0.6869 - val_loss: 0.2286 - val_accuracy: 0.9329 - lr: 5.0000e-04\n",
      "Epoch 44/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.9611 - accuracy: 0.6890 - val_loss: 0.2207 - val_accuracy: 0.9332 - lr: 5.0000e-04\n",
      "Epoch 45/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9577 - accuracy: 0.6889 - val_loss: 0.2416 - val_accuracy: 0.9260 - lr: 5.0000e-04\n",
      "Epoch 46/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9480 - accuracy: 0.6916 - val_loss: 0.2289 - val_accuracy: 0.9316 - lr: 5.0000e-04\n",
      "Epoch 47/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9425 - accuracy: 0.6956 - val_loss: 0.2144 - val_accuracy: 0.9352 - lr: 5.0000e-04\n",
      "Epoch 48/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9430 - accuracy: 0.6964 - val_loss: 0.2154 - val_accuracy: 0.9356 - lr: 5.0000e-04\n",
      "Epoch 49/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9315 - accuracy: 0.6996 - val_loss: 0.2227 - val_accuracy: 0.9315 - lr: 5.0000e-04\n",
      "Epoch 50/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9330 - accuracy: 0.6965 - val_loss: 0.2044 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 51/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9263 - accuracy: 0.7007 - val_loss: 0.2198 - val_accuracy: 0.9328 - lr: 5.0000e-04\n",
      "Epoch 52/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9209 - accuracy: 0.7034 - val_loss: 0.2046 - val_accuracy: 0.9404 - lr: 5.0000e-04\n",
      "Epoch 53/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9147 - accuracy: 0.7038 - val_loss: 0.2035 - val_accuracy: 0.9360 - lr: 5.0000e-04\n",
      "Epoch 54/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9109 - accuracy: 0.7067 - val_loss: 0.2055 - val_accuracy: 0.9369 - lr: 5.0000e-04\n",
      "Epoch 55/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9125 - accuracy: 0.7049 - val_loss: 0.1958 - val_accuracy: 0.9407 - lr: 5.0000e-04\n",
      "Epoch 56/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9121 - accuracy: 0.7064 - val_loss: 0.1973 - val_accuracy: 0.9418 - lr: 5.0000e-04\n",
      "Epoch 57/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.9026 - accuracy: 0.7084 - val_loss: 0.2012 - val_accuracy: 0.9397 - lr: 5.0000e-04\n",
      "Epoch 58/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8957 - accuracy: 0.7094 - val_loss: 0.1895 - val_accuracy: 0.9428 - lr: 5.0000e-04\n",
      "Epoch 59/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8980 - accuracy: 0.7068 - val_loss: 0.1938 - val_accuracy: 0.9424 - lr: 5.0000e-04\n",
      "Epoch 60/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8930 - accuracy: 0.7102 - val_loss: 0.1867 - val_accuracy: 0.9461 - lr: 5.0000e-04\n",
      "Epoch 61/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.8945 - accuracy: 0.7115 - val_loss: 0.2052 - val_accuracy: 0.9381 - lr: 5.0000e-04\n",
      "Epoch 62/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8825 - accuracy: 0.7172 - val_loss: 0.2247 - val_accuracy: 0.9319 - lr: 5.0000e-04\n",
      "Epoch 63/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.8801 - accuracy: 0.7150 - val_loss: 0.1954 - val_accuracy: 0.9410 - lr: 5.0000e-04\n",
      "Epoch 64/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8635 - accuracy: 0.7200 - val_loss: 0.1823 - val_accuracy: 0.9449 - lr: 2.5000e-04\n",
      "Epoch 65/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.8526 - accuracy: 0.7243 - val_loss: 0.1819 - val_accuracy: 0.9469 - lr: 2.5000e-04\n",
      "Epoch 66/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8475 - accuracy: 0.7273 - val_loss: 0.1813 - val_accuracy: 0.9468 - lr: 2.5000e-04\n",
      "Epoch 67/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8478 - accuracy: 0.7258 - val_loss: 0.1800 - val_accuracy: 0.9464 - lr: 2.5000e-04\n",
      "Epoch 68/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8402 - accuracy: 0.7267 - val_loss: 0.1863 - val_accuracy: 0.9452 - lr: 2.5000e-04\n",
      "Epoch 69/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.8378 - accuracy: 0.7290 - val_loss: 0.1754 - val_accuracy: 0.9471 - lr: 2.5000e-04\n",
      "Epoch 70/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8372 - accuracy: 0.7296 - val_loss: 0.1803 - val_accuracy: 0.9462 - lr: 2.5000e-04\n",
      "Epoch 71/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.8334 - accuracy: 0.7293 - val_loss: 0.1746 - val_accuracy: 0.9479 - lr: 2.5000e-04\n",
      "Epoch 72/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.8310 - accuracy: 0.7309 - val_loss: 0.1814 - val_accuracy: 0.9460 - lr: 2.5000e-04\n",
      "Epoch 73/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8240 - accuracy: 0.7355 - val_loss: 0.1690 - val_accuracy: 0.9487 - lr: 2.5000e-04\n",
      "Epoch 74/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8333 - accuracy: 0.7294 - val_loss: 0.1757 - val_accuracy: 0.9465 - lr: 2.5000e-04\n",
      "Epoch 75/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8203 - accuracy: 0.7352 - val_loss: 0.1774 - val_accuracy: 0.9460 - lr: 2.5000e-04\n",
      "Epoch 76/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8202 - accuracy: 0.7351 - val_loss: 0.1696 - val_accuracy: 0.9493 - lr: 2.5000e-04\n",
      "Epoch 77/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.8245 - accuracy: 0.7353 - val_loss: 0.1700 - val_accuracy: 0.9487 - lr: 1.2500e-04\n",
      "Epoch 78/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8192 - accuracy: 0.7350 - val_loss: 0.1681 - val_accuracy: 0.9488 - lr: 1.2500e-04\n",
      "Epoch 79/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8106 - accuracy: 0.7394 - val_loss: 0.1643 - val_accuracy: 0.9504 - lr: 1.2500e-04\n",
      "Epoch 80/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8028 - accuracy: 0.7399 - val_loss: 0.1630 - val_accuracy: 0.9518 - lr: 1.2500e-04\n",
      "Epoch 81/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8102 - accuracy: 0.7371 - val_loss: 0.1632 - val_accuracy: 0.9505 - lr: 1.2500e-04\n",
      "Epoch 82/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8022 - accuracy: 0.7421 - val_loss: 0.1677 - val_accuracy: 0.9489 - lr: 1.2500e-04\n",
      "Epoch 83/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7993 - accuracy: 0.7422 - val_loss: 0.1658 - val_accuracy: 0.9513 - lr: 1.2500e-04\n",
      "Epoch 84/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.8011 - accuracy: 0.7407 - val_loss: 0.1673 - val_accuracy: 0.9496 - lr: 1.0000e-04\n",
      "Epoch 85/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7916 - accuracy: 0.7439 - val_loss: 0.1660 - val_accuracy: 0.9502 - lr: 1.0000e-04\n",
      "Epoch 86/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7920 - accuracy: 0.7416 - val_loss: 0.1623 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 87/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7961 - accuracy: 0.7418 - val_loss: 0.1648 - val_accuracy: 0.9500 - lr: 1.0000e-04\n",
      "Epoch 88/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7960 - accuracy: 0.7420 - val_loss: 0.1618 - val_accuracy: 0.9502 - lr: 1.0000e-04\n",
      "Epoch 89/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7949 - accuracy: 0.7445 - val_loss: 0.1558 - val_accuracy: 0.9520 - lr: 1.0000e-04\n",
      "Epoch 90/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7913 - accuracy: 0.7460 - val_loss: 0.1658 - val_accuracy: 0.9492 - lr: 1.0000e-04\n",
      "Epoch 91/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7953 - accuracy: 0.7437 - val_loss: 0.1626 - val_accuracy: 0.9501 - lr: 1.0000e-04\n",
      "Epoch 92/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7886 - accuracy: 0.7440 - val_loss: 0.1615 - val_accuracy: 0.9502 - lr: 1.0000e-04\n",
      "Epoch 93/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7859 - accuracy: 0.7459 - val_loss: 0.1564 - val_accuracy: 0.9522 - lr: 1.0000e-04\n",
      "Epoch 94/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7828 - accuracy: 0.7473 - val_loss: 0.1573 - val_accuracy: 0.9515 - lr: 1.0000e-04\n",
      "Epoch 95/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7877 - accuracy: 0.7465 - val_loss: 0.1554 - val_accuracy: 0.9528 - lr: 1.0000e-04\n",
      "Epoch 96/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7841 - accuracy: 0.7464 - val_loss: 0.1591 - val_accuracy: 0.9517 - lr: 1.0000e-04\n",
      "Epoch 97/300\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.7803 - accuracy: 0.7468 - val_loss: 0.1554 - val_accuracy: 0.9518 - lr: 1.0000e-04\n",
      "Epoch 98/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7808 - accuracy: 0.7476 - val_loss: 0.1589 - val_accuracy: 0.9521 - lr: 1.0000e-04\n",
      "Epoch 99/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7845 - accuracy: 0.7474 - val_loss: 0.1549 - val_accuracy: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 100/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7779 - accuracy: 0.7496 - val_loss: 0.1560 - val_accuracy: 0.9525 - lr: 1.0000e-04\n",
      "Epoch 101/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7856 - accuracy: 0.7466 - val_loss: 0.1588 - val_accuracy: 0.9522 - lr: 1.0000e-04\n",
      "Epoch 102/300\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.7805 - accuracy: 0.7497 - val_loss: 0.1583 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 103/300\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.7873 - accuracy: 0.7459 - val_loss: 0.1579 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 104/300\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.7791 - accuracy: 0.7502 - val_loss: 0.1571 - val_accuracy: 0.9515 - lr: 1.0000e-04\n",
      "Epoch 105/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7743 - accuracy: 0.7501 - val_loss: 0.1583 - val_accuracy: 0.9511 - lr: 1.0000e-04\n",
      "Epoch 106/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7821 - accuracy: 0.7450 - val_loss: 0.1536 - val_accuracy: 0.9533 - lr: 1.0000e-04\n",
      "Epoch 107/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7727 - accuracy: 0.7497 - val_loss: 0.1548 - val_accuracy: 0.9526 - lr: 1.0000e-04\n",
      "Epoch 108/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7728 - accuracy: 0.7516 - val_loss: 0.1543 - val_accuracy: 0.9528 - lr: 1.0000e-04\n",
      "Epoch 109/300\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.7772 - accuracy: 0.7503 - val_loss: 0.1533 - val_accuracy: 0.9527 - lr: 1.0000e-04\n",
      "Epoch 110/300\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.7749 - accuracy: 0.7484 - val_loss: 0.1518 - val_accuracy: 0.9536 - lr: 1.0000e-04\n",
      "Epoch 111/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7732 - accuracy: 0.7503 - val_loss: 0.1541 - val_accuracy: 0.9525 - lr: 1.0000e-04\n",
      "Epoch 112/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7709 - accuracy: 0.7514 - val_loss: 0.1527 - val_accuracy: 0.9524 - lr: 1.0000e-04\n",
      "Epoch 113/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7772 - accuracy: 0.7513 - val_loss: 0.1540 - val_accuracy: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 114/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7632 - accuracy: 0.7547 - val_loss: 0.1542 - val_accuracy: 0.9520 - lr: 1.0000e-04\n",
      "Epoch 115/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7701 - accuracy: 0.7498 - val_loss: 0.1490 - val_accuracy: 0.9550 - lr: 1.0000e-04\n",
      "Epoch 116/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7693 - accuracy: 0.7522 - val_loss: 0.1532 - val_accuracy: 0.9526 - lr: 1.0000e-04\n",
      "Epoch 117/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7690 - accuracy: 0.7529 - val_loss: 0.1504 - val_accuracy: 0.9539 - lr: 1.0000e-04\n",
      "Epoch 118/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7718 - accuracy: 0.7519 - val_loss: 0.1508 - val_accuracy: 0.9542 - lr: 1.0000e-04\n",
      "Epoch 119/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7727 - accuracy: 0.7510 - val_loss: 0.1497 - val_accuracy: 0.9536 - lr: 1.0000e-04\n",
      "Epoch 120/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7669 - accuracy: 0.7516 - val_loss: 0.1511 - val_accuracy: 0.9538 - lr: 1.0000e-04\n",
      "Epoch 121/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7679 - accuracy: 0.7526 - val_loss: 0.1501 - val_accuracy: 0.9547 - lr: 1.0000e-04\n",
      "Epoch 122/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7694 - accuracy: 0.7524 - val_loss: 0.1494 - val_accuracy: 0.9535 - lr: 1.0000e-04\n",
      "Epoch 123/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7701 - accuracy: 0.7524 - val_loss: 0.1459 - val_accuracy: 0.9558 - lr: 1.0000e-04\n",
      "Epoch 124/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7654 - accuracy: 0.7514 - val_loss: 0.1525 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 125/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7658 - accuracy: 0.7519 - val_loss: 0.1546 - val_accuracy: 0.9521 - lr: 1.0000e-04\n",
      "Epoch 126/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7633 - accuracy: 0.7524 - val_loss: 0.1525 - val_accuracy: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 127/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7672 - accuracy: 0.7529 - val_loss: 0.1552 - val_accuracy: 0.9517 - lr: 1.0000e-04\n",
      "Epoch 128/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7604 - accuracy: 0.7558 - val_loss: 0.1466 - val_accuracy: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 129/300\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.7625 - accuracy: 0.7530 - val_loss: 0.1481 - val_accuracy: 0.9530 - lr: 1.0000e-04\n",
      "Epoch 130/300\n",
      "469/469 [==============================] - 16s 34ms/step - loss: 0.7644 - accuracy: 0.7516 - val_loss: 0.1499 - val_accuracy: 0.9536 - lr: 1.0000e-04\n",
      "Epoch 131/300\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.7577 - accuracy: 0.7550 - val_loss: 0.1482 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1459 - accuracy: 0.9558\n",
      "Test Loss: 0.1459, Test Accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Input, LeakyReLU\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据预处理：归一化\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)  # 保持原始图像形状并添加通道维度\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 数据增强\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    zoom_range=0.4,\n",
    "    shear_range=0.4,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 构建改进后的BP神经网络模型\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(28, 28, 1)),  # 使用Input层指定输入形状\n",
    "        Flatten(),  # 展平图像\n",
    "\n",
    "        Dense(2048),  # 输入层 -> 隐藏层 1\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(1024),  # 隐藏层 2\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(512),  # 隐藏层 3\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(256),  # 隐藏层 4\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(128),  # 隐藏层 5\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(64),  # 隐藏层 6\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(32),  # 隐藏层 7\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(10, activation=\"softmax\"),  # 输出层\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),  # 使用RMSprop优化器\n",
    "    loss=\"categorical_crossentropy\",  # 多分类交叉熵损失\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 回调函数\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=8, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=128),  # 调整批量大小\n",
    "    epochs=300,  # 增加训练轮数\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# 测试模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "model.save(\"mnist_model_bp_v4.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
