{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e27b176-d698-4e04-8b27-78f53d0265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinbob/PycharmProjects/tensorflow-sample/env/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/Users/xinbob/PycharmProjects/tensorflow-sample/env/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 69ms/step - accuracy: 0.3239 - loss: 2.1558 - val_accuracy: 0.9099 - val_loss: 0.3242 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - accuracy: 0.7847 - loss: 0.7369 - val_accuracy: 0.9521 - val_loss: 0.1710 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 68ms/step - accuracy: 0.8578 - loss: 0.5444 - val_accuracy: 0.9612 - val_loss: 0.1449 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 69ms/step - accuracy: 0.8868 - loss: 0.4549 - val_accuracy: 0.9661 - val_loss: 0.1263 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.8979 - loss: 0.4108 - val_accuracy: 0.9707 - val_loss: 0.1111 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9057 - loss: 0.3927 - val_accuracy: 0.9720 - val_loss: 0.1090 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9132 - loss: 0.3658 - val_accuracy: 0.9734 - val_loss: 0.1005 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9159 - loss: 0.3488 - val_accuracy: 0.9766 - val_loss: 0.0884 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9225 - loss: 0.3288 - val_accuracy: 0.9766 - val_loss: 0.0881 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9269 - loss: 0.3130 - val_accuracy: 0.9770 - val_loss: 0.0860 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9286 - loss: 0.3095 - val_accuracy: 0.9808 - val_loss: 0.0725 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9347 - loss: 0.2861 - val_accuracy: 0.9778 - val_loss: 0.0817 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9340 - loss: 0.2882 - val_accuracy: 0.9798 - val_loss: 0.0754 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9358 - loss: 0.2770 - val_accuracy: 0.9829 - val_loss: 0.0716 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9368 - loss: 0.2754 - val_accuracy: 0.9770 - val_loss: 0.0900 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9389 - loss: 0.2720 - val_accuracy: 0.9802 - val_loss: 0.0736 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 70ms/step - accuracy: 0.9404 - loss: 0.2631 - val_accuracy: 0.9824 - val_loss: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 71ms/step - accuracy: 0.9433 - loss: 0.2504 - val_accuracy: 0.9834 - val_loss: 0.0669 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 70ms/step - accuracy: 0.9426 - loss: 0.2551 - val_accuracy: 0.9836 - val_loss: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9441 - loss: 0.2472 - val_accuracy: 0.9840 - val_loss: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9443 - loss: 0.2384 - val_accuracy: 0.9846 - val_loss: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9476 - loss: 0.2341 - val_accuracy: 0.9825 - val_loss: 0.0666 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9468 - loss: 0.2284 - val_accuracy: 0.9857 - val_loss: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9488 - loss: 0.2231 - val_accuracy: 0.9846 - val_loss: 0.0590 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9467 - loss: 0.2293 - val_accuracy: 0.9837 - val_loss: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9518 - loss: 0.2201 - val_accuracy: 0.9862 - val_loss: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9505 - loss: 0.2176 - val_accuracy: 0.9854 - val_loss: 0.0574 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9488 - loss: 0.2246 - val_accuracy: 0.9861 - val_loss: 0.0552 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9506 - loss: 0.2163 - val_accuracy: 0.9878 - val_loss: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - accuracy: 0.9501 - loss: 0.2214 - val_accuracy: 0.9863 - val_loss: 0.0519 - learning_rate: 0.0010\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0581\n",
      "Test accuracy: 0.9878000020980835\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    ")\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据预处理：归一化\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)  # 调整形状以匹配模型输入\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 数据增强\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "datagen.fit(x_train.reshape(-1, 28, 28, 1))  # 数据增强需要原始形状\n",
    "\n",
    "# 构建多层感知机（MLP）神经网络模型\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(28, 28, 1)),  # 输入层\n",
    "        tf.keras.layers.Flatten(),  # 展平图像\n",
    "        Dense(2048),  # 隐藏层 1\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(1024),  # 隐藏层 2\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(512),  # 隐藏层 3\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(256),  # 隐藏层 4\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(128),  # 隐藏层 5\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(64),  # 隐藏层 6\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(32),  # 隐藏层 7\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(10, activation=\"softmax\"),  # 输出层\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),  # 使用RMSprop优化器\n",
    "    loss=\"categorical_crossentropy\",  # 多分类交叉熵损失\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 回调函数\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=3, min_lr=0.00001\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=8, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train.reshape(-1, 28, 28, 1), y_train, batch_size=128),  # 调整批量大小并恢复原始形状\n",
    "    epochs=30,  # 增加训练轮数\n",
    "    validation_data=(x_test.reshape(-1, 28, 28, 1), y_test),  # 恢复原始形状\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)  # 使用调整后的测试数据形状\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# 保存模型\n",
    "model.save(\"mnist_model_mlp.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
