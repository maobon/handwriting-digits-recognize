{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e27b176-d698-4e04-8b27-78f53d0265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 22:43:26.708490: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-01-12 22:43:26.708522: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-01-12 22:43:26.708529: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-01-12 22:43:26.708561: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-12 22:43:26.708578: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 22:43:27.835757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935/937 [============================>.] - ETA: 0s - loss: 2.2863 - accuracy: 0.1894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 22:43:53.060161: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937/937 [==============================] - 28s 26ms/step - loss: 2.2857 - accuracy: 0.1895 - val_loss: 1.7299 - val_accuracy: 0.3913 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 1.8126 - accuracy: 0.3418 - val_loss: 1.1754 - val_accuracy: 0.5407 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 1.5492 - accuracy: 0.4576 - val_loss: 0.9117 - val_accuracy: 0.6707 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 1.3950 - accuracy: 0.5185 - val_loss: 0.7789 - val_accuracy: 0.7358 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 1.2880 - accuracy: 0.5638 - val_loss: 0.6735 - val_accuracy: 0.8001 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 1.1851 - accuracy: 0.6129 - val_loss: 0.4725 - val_accuracy: 0.8657 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 1.0927 - accuracy: 0.6483 - val_loss: 0.4776 - val_accuracy: 0.8577 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 1.0262 - accuracy: 0.6725 - val_loss: 0.3518 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.9648 - accuracy: 0.6954 - val_loss: 0.2760 - val_accuracy: 0.9240 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.9260 - accuracy: 0.7103 - val_loss: 0.2633 - val_accuracy: 0.9241 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.8869 - accuracy: 0.7222 - val_loss: 0.2460 - val_accuracy: 0.9283 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.8556 - accuracy: 0.7348 - val_loss: 0.2169 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.8247 - accuracy: 0.7434 - val_loss: 0.2541 - val_accuracy: 0.9217 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.8073 - accuracy: 0.7470 - val_loss: 0.1982 - val_accuracy: 0.9429 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.7779 - accuracy: 0.7573 - val_loss: 0.2244 - val_accuracy: 0.9319 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.7638 - accuracy: 0.7619 - val_loss: 0.2112 - val_accuracy: 0.9404 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.7501 - accuracy: 0.7675 - val_loss: 0.1818 - val_accuracy: 0.9492 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.7240 - accuracy: 0.7756 - val_loss: 0.1640 - val_accuracy: 0.9502 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "937/937 [==============================] - 27s 28ms/step - loss: 0.7142 - accuracy: 0.7775 - val_loss: 0.1844 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.7060 - accuracy: 0.7797 - val_loss: 0.1519 - val_accuracy: 0.9553 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.6927 - accuracy: 0.7841 - val_loss: 0.1903 - val_accuracy: 0.9467 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.6781 - accuracy: 0.7889 - val_loss: 0.1574 - val_accuracy: 0.9515 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.6705 - accuracy: 0.7910 - val_loss: 0.1351 - val_accuracy: 0.9587 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.6530 - accuracy: 0.7962 - val_loss: 0.1364 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.6528 - accuracy: 0.7970 - val_loss: 0.1487 - val_accuracy: 0.9576 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.6367 - accuracy: 0.8011 - val_loss: 0.1424 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.6251 - accuracy: 0.8036 - val_loss: 0.1334 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.6328 - accuracy: 0.8018 - val_loss: 0.1815 - val_accuracy: 0.9452 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.6085 - accuracy: 0.8111 - val_loss: 0.1154 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.6068 - accuracy: 0.8086 - val_loss: 0.1234 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.6035 - accuracy: 0.8107 - val_loss: 0.1333 - val_accuracy: 0.9614 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.5927 - accuracy: 0.8151 - val_loss: 0.1206 - val_accuracy: 0.9643 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.5866 - accuracy: 0.8167 - val_loss: 0.1608 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.5895 - accuracy: 0.8160 - val_loss: 0.1306 - val_accuracy: 0.9609 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.5838 - accuracy: 0.8190 - val_loss: 0.1149 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5787 - accuracy: 0.8200 - val_loss: 0.1231 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.5719 - accuracy: 0.8225 - val_loss: 0.1370 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.5715 - accuracy: 0.8222 - val_loss: 0.1141 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.5568 - accuracy: 0.8261 - val_loss: 0.1261 - val_accuracy: 0.9608 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.5522 - accuracy: 0.8279 - val_loss: 0.1167 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5524 - accuracy: 0.8269 - val_loss: 0.1018 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.5453 - accuracy: 0.8287 - val_loss: 0.1259 - val_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5375 - accuracy: 0.8335 - val_loss: 0.1160 - val_accuracy: 0.9653 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.5376 - accuracy: 0.8328 - val_loss: 0.1153 - val_accuracy: 0.9638 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.5329 - accuracy: 0.8337 - val_loss: 0.0990 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.5294 - accuracy: 0.8355 - val_loss: 0.1047 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.5307 - accuracy: 0.8350 - val_loss: 0.1115 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5192 - accuracy: 0.8383 - val_loss: 0.1060 - val_accuracy: 0.9691 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5208 - accuracy: 0.8369 - val_loss: 0.0950 - val_accuracy: 0.9708 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5144 - accuracy: 0.8403 - val_loss: 0.1072 - val_accuracy: 0.9678 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5172 - accuracy: 0.8380 - val_loss: 0.1087 - val_accuracy: 0.9647 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5115 - accuracy: 0.8414 - val_loss: 0.1084 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5077 - accuracy: 0.8422 - val_loss: 0.1257 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5047 - accuracy: 0.8434 - val_loss: 0.0982 - val_accuracy: 0.9712 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.5075 - accuracy: 0.8417 - val_loss: 0.1269 - val_accuracy: 0.9638 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4971 - accuracy: 0.8450 - val_loss: 0.0940 - val_accuracy: 0.9699 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4929 - accuracy: 0.8454 - val_loss: 0.0965 - val_accuracy: 0.9721 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4938 - accuracy: 0.8460 - val_loss: 0.0943 - val_accuracy: 0.9721 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.4960 - accuracy: 0.8453 - val_loss: 0.0903 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "937/937 [==============================] - 27s 28ms/step - loss: 0.4927 - accuracy: 0.8469 - val_loss: 0.0928 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.4823 - accuracy: 0.8502 - val_loss: 0.1018 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4831 - accuracy: 0.8491 - val_loss: 0.1033 - val_accuracy: 0.9694 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.4877 - accuracy: 0.8474 - val_loss: 0.0957 - val_accuracy: 0.9710 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.4825 - accuracy: 0.8493 - val_loss: 0.0946 - val_accuracy: 0.9705 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.4745 - accuracy: 0.8529 - val_loss: 0.1131 - val_accuracy: 0.9653 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.4736 - accuracy: 0.8527 - val_loss: 0.0979 - val_accuracy: 0.9699 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4718 - accuracy: 0.8526 - val_loss: 0.0886 - val_accuracy: 0.9724 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.4686 - accuracy: 0.8539 - val_loss: 0.0901 - val_accuracy: 0.9717 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "937/937 [==============================] - 26s 27ms/step - loss: 0.4658 - accuracy: 0.8555 - val_loss: 0.0868 - val_accuracy: 0.9732 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4705 - accuracy: 0.8535 - val_loss: 0.0772 - val_accuracy: 0.9761 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4670 - accuracy: 0.8547 - val_loss: 0.0966 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4613 - accuracy: 0.8563 - val_loss: 0.0836 - val_accuracy: 0.9744 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.4629 - accuracy: 0.8563 - val_loss: 0.0944 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.4541 - accuracy: 0.8579 - val_loss: 0.0841 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.4544 - accuracy: 0.8581 - val_loss: 0.0925 - val_accuracy: 0.9697 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4601 - accuracy: 0.8554 - val_loss: 0.1149 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4592 - accuracy: 0.8577 - val_loss: 0.0999 - val_accuracy: 0.9694 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.8600\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "937/937 [==============================] - 26s 27ms/step - loss: 0.4500 - accuracy: 0.8600 - val_loss: 0.0888 - val_accuracy: 0.9715 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.4213 - accuracy: 0.8684 - val_loss: 0.0754 - val_accuracy: 0.9755 - lr: 5.0000e-04\n",
      "Epoch 80/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4080 - accuracy: 0.8736 - val_loss: 0.0896 - val_accuracy: 0.9716 - lr: 5.0000e-04\n",
      "Epoch 81/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4111 - accuracy: 0.8722 - val_loss: 0.0744 - val_accuracy: 0.9773 - lr: 5.0000e-04\n",
      "Epoch 82/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.4045 - accuracy: 0.8742 - val_loss: 0.0764 - val_accuracy: 0.9758 - lr: 5.0000e-04\n",
      "Epoch 83/300\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.3965 - accuracy: 0.8761 - val_loss: 0.0805 - val_accuracy: 0.9750 - lr: 5.0000e-04\n",
      "Epoch 84/300\n",
      "937/937 [==============================] - 28s 29ms/step - loss: 0.3976 - accuracy: 0.8765 - val_loss: 0.0680 - val_accuracy: 0.9783 - lr: 5.0000e-04\n",
      "Epoch 85/300\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.4011 - accuracy: 0.8745 - val_loss: 0.0758 - val_accuracy: 0.9760 - lr: 5.0000e-04\n",
      "Epoch 86/300\n",
      "937/937 [==============================] - 27s 29ms/step - loss: 0.3963 - accuracy: 0.8758 - val_loss: 0.0732 - val_accuracy: 0.9780 - lr: 5.0000e-04\n",
      "Epoch 87/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3951 - accuracy: 0.8792 - val_loss: 0.0726 - val_accuracy: 0.9778 - lr: 5.0000e-04\n",
      "Epoch 88/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3993 - accuracy: 0.8762 - val_loss: 0.0749 - val_accuracy: 0.9774 - lr: 5.0000e-04\n",
      "Epoch 89/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3963 - accuracy: 0.8763 - val_loss: 0.0785 - val_accuracy: 0.9760 - lr: 5.0000e-04\n",
      "Epoch 90/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3910 - accuracy: 0.8785 - val_loss: 0.0714 - val_accuracy: 0.9792 - lr: 5.0000e-04\n",
      "Epoch 91/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3928 - accuracy: 0.8773 - val_loss: 0.0710 - val_accuracy: 0.9784 - lr: 5.0000e-04\n",
      "Epoch 92/300\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8776\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3907 - accuracy: 0.8775 - val_loss: 0.0711 - val_accuracy: 0.9777 - lr: 5.0000e-04\n",
      "Epoch 93/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3732 - accuracy: 0.8838 - val_loss: 0.0637 - val_accuracy: 0.9800 - lr: 2.5000e-04\n",
      "Epoch 94/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3689 - accuracy: 0.8863 - val_loss: 0.0683 - val_accuracy: 0.9788 - lr: 2.5000e-04\n",
      "Epoch 95/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3694 - accuracy: 0.8852 - val_loss: 0.0725 - val_accuracy: 0.9787 - lr: 2.5000e-04\n",
      "Epoch 96/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3673 - accuracy: 0.8869 - val_loss: 0.0672 - val_accuracy: 0.9791 - lr: 2.5000e-04\n",
      "Epoch 97/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3654 - accuracy: 0.8862 - val_loss: 0.0683 - val_accuracy: 0.9786 - lr: 2.5000e-04\n",
      "Epoch 98/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3650 - accuracy: 0.8862 - val_loss: 0.0655 - val_accuracy: 0.9793 - lr: 2.5000e-04\n",
      "Epoch 99/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3626 - accuracy: 0.8877 - val_loss: 0.0671 - val_accuracy: 0.9792 - lr: 2.5000e-04\n",
      "Epoch 100/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3571 - accuracy: 0.8902 - val_loss: 0.0616 - val_accuracy: 0.9810 - lr: 2.5000e-04\n",
      "Epoch 101/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3622 - accuracy: 0.8872 - val_loss: 0.0630 - val_accuracy: 0.9806 - lr: 2.5000e-04\n",
      "Epoch 102/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3605 - accuracy: 0.8867 - val_loss: 0.0627 - val_accuracy: 0.9804 - lr: 2.5000e-04\n",
      "Epoch 103/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3592 - accuracy: 0.8886 - val_loss: 0.0636 - val_accuracy: 0.9801 - lr: 2.5000e-04\n",
      "Epoch 104/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3553 - accuracy: 0.8893 - val_loss: 0.0663 - val_accuracy: 0.9795 - lr: 2.5000e-04\n",
      "Epoch 105/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3583 - accuracy: 0.8880 - val_loss: 0.0683 - val_accuracy: 0.9792 - lr: 2.5000e-04\n",
      "Epoch 106/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3565 - accuracy: 0.8876 - val_loss: 0.0638 - val_accuracy: 0.9801 - lr: 2.5000e-04\n",
      "Epoch 107/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3591 - accuracy: 0.8888 - val_loss: 0.0626 - val_accuracy: 0.9803 - lr: 2.5000e-04\n",
      "Epoch 108/300\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.3591 - accuracy: 0.8892\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3591 - accuracy: 0.8892 - val_loss: 0.0645 - val_accuracy: 0.9804 - lr: 2.5000e-04\n",
      "Epoch 109/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3464 - accuracy: 0.8918 - val_loss: 0.0624 - val_accuracy: 0.9821 - lr: 1.2500e-04\n",
      "Epoch 110/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3424 - accuracy: 0.8930 - val_loss: 0.0618 - val_accuracy: 0.9810 - lr: 1.2500e-04\n",
      "Epoch 111/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3410 - accuracy: 0.8935 - val_loss: 0.0600 - val_accuracy: 0.9824 - lr: 1.2500e-04\n",
      "Epoch 112/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3488 - accuracy: 0.8929 - val_loss: 0.0605 - val_accuracy: 0.9817 - lr: 1.2500e-04\n",
      "Epoch 113/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3452 - accuracy: 0.8924 - val_loss: 0.0579 - val_accuracy: 0.9821 - lr: 1.2500e-04\n",
      "Epoch 114/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3393 - accuracy: 0.8943 - val_loss: 0.0579 - val_accuracy: 0.9819 - lr: 1.2500e-04\n",
      "Epoch 115/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3431 - accuracy: 0.8940 - val_loss: 0.0606 - val_accuracy: 0.9823 - lr: 1.2500e-04\n",
      "Epoch 116/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3372 - accuracy: 0.8948 - val_loss: 0.0611 - val_accuracy: 0.9813 - lr: 1.2500e-04\n",
      "Epoch 117/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3441 - accuracy: 0.8937 - val_loss: 0.0604 - val_accuracy: 0.9816 - lr: 1.2500e-04\n",
      "Epoch 118/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3459 - accuracy: 0.8928 - val_loss: 0.0620 - val_accuracy: 0.9817 - lr: 1.2500e-04\n",
      "Epoch 119/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3353 - accuracy: 0.8956 - val_loss: 0.0602 - val_accuracy: 0.9814 - lr: 1.2500e-04\n",
      "Epoch 120/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3410 - accuracy: 0.8946 - val_loss: 0.0623 - val_accuracy: 0.9811 - lr: 1.2500e-04\n",
      "Epoch 121/300\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8961\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3366 - accuracy: 0.8961 - val_loss: 0.0592 - val_accuracy: 0.9823 - lr: 1.2500e-04\n",
      "Epoch 122/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3341 - accuracy: 0.8958 - val_loss: 0.0600 - val_accuracy: 0.9816 - lr: 6.2500e-05\n",
      "Epoch 123/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3308 - accuracy: 0.8981 - val_loss: 0.0603 - val_accuracy: 0.9818 - lr: 6.2500e-05\n",
      "Epoch 124/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3317 - accuracy: 0.8970 - val_loss: 0.0592 - val_accuracy: 0.9820 - lr: 6.2500e-05\n",
      "Epoch 125/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3306 - accuracy: 0.8978 - val_loss: 0.0575 - val_accuracy: 0.9827 - lr: 6.2500e-05\n",
      "Epoch 126/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3365 - accuracy: 0.8951 - val_loss: 0.0597 - val_accuracy: 0.9812 - lr: 6.2500e-05\n",
      "Epoch 127/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3349 - accuracy: 0.8953 - val_loss: 0.0602 - val_accuracy: 0.9816 - lr: 6.2500e-05\n",
      "Epoch 128/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3340 - accuracy: 0.8974 - val_loss: 0.0588 - val_accuracy: 0.9823 - lr: 6.2500e-05\n",
      "Epoch 129/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3331 - accuracy: 0.8961 - val_loss: 0.0592 - val_accuracy: 0.9817 - lr: 6.2500e-05\n",
      "Epoch 130/300\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.3344 - accuracy: 0.8961 - val_loss: 0.0583 - val_accuracy: 0.9829 - lr: 6.2500e-05\n",
      "Epoch 131/300\n",
      "937/937 [==============================] - 26s 28ms/step - loss: 0.3273 - accuracy: 0.8977 - val_loss: 0.0587 - val_accuracy: 0.9823 - lr: 6.2500e-05\n",
      "Epoch 132/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3342 - accuracy: 0.8962 - val_loss: 0.0586 - val_accuracy: 0.9824 - lr: 6.2500e-05\n",
      "Epoch 133/300\n",
      "937/937 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8970\n",
      "Epoch 133: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3302 - accuracy: 0.8970 - val_loss: 0.0583 - val_accuracy: 0.9825 - lr: 6.2500e-05\n",
      "Epoch 134/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3319 - accuracy: 0.8964 - val_loss: 0.0586 - val_accuracy: 0.9831 - lr: 3.1250e-05\n",
      "Epoch 135/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3246 - accuracy: 0.8991 - val_loss: 0.0568 - val_accuracy: 0.9831 - lr: 3.1250e-05\n",
      "Epoch 136/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3246 - accuracy: 0.8983 - val_loss: 0.0566 - val_accuracy: 0.9833 - lr: 3.1250e-05\n",
      "Epoch 137/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3237 - accuracy: 0.8985 - val_loss: 0.0564 - val_accuracy: 0.9827 - lr: 3.1250e-05\n",
      "Epoch 138/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3245 - accuracy: 0.8985 - val_loss: 0.0569 - val_accuracy: 0.9830 - lr: 3.1250e-05\n",
      "Epoch 139/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3232 - accuracy: 0.9001 - val_loss: 0.0595 - val_accuracy: 0.9818 - lr: 3.1250e-05\n",
      "Epoch 140/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3296 - accuracy: 0.8975 - val_loss: 0.0580 - val_accuracy: 0.9822 - lr: 3.1250e-05\n",
      "Epoch 141/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3228 - accuracy: 0.8997 - val_loss: 0.0566 - val_accuracy: 0.9828 - lr: 3.1250e-05\n",
      "Epoch 142/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3241 - accuracy: 0.8999 - val_loss: 0.0574 - val_accuracy: 0.9827 - lr: 3.1250e-05\n",
      "Epoch 143/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3215 - accuracy: 0.8998 - val_loss: 0.0570 - val_accuracy: 0.9826 - lr: 3.1250e-05\n",
      "Epoch 144/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3282 - accuracy: 0.8980 - val_loss: 0.0563 - val_accuracy: 0.9826 - lr: 3.1250e-05\n",
      "Epoch 145/300\n",
      "936/937 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.8991\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3242 - accuracy: 0.8992 - val_loss: 0.0574 - val_accuracy: 0.9826 - lr: 3.1250e-05\n",
      "Epoch 146/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3205 - accuracy: 0.8992 - val_loss: 0.0581 - val_accuracy: 0.9824 - lr: 1.5625e-05\n",
      "Epoch 147/300\n",
      "937/937 [==============================] - 24s 25ms/step - loss: 0.3278 - accuracy: 0.8985 - val_loss: 0.0575 - val_accuracy: 0.9829 - lr: 1.5625e-05\n",
      "Epoch 148/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3232 - accuracy: 0.9002 - val_loss: 0.0583 - val_accuracy: 0.9825 - lr: 1.5625e-05\n",
      "Epoch 149/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3226 - accuracy: 0.8989 - val_loss: 0.0566 - val_accuracy: 0.9829 - lr: 1.5625e-05\n",
      "Epoch 150/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3269 - accuracy: 0.8986 - val_loss: 0.0576 - val_accuracy: 0.9827 - lr: 1.5625e-05\n",
      "Epoch 151/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3213 - accuracy: 0.9007 - val_loss: 0.0579 - val_accuracy: 0.9827 - lr: 1.5625e-05\n",
      "Epoch 152/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3241 - accuracy: 0.9008 - val_loss: 0.0558 - val_accuracy: 0.9832 - lr: 1.5625e-05\n",
      "Epoch 153/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3307 - accuracy: 0.8980 - val_loss: 0.0571 - val_accuracy: 0.9828 - lr: 1.5625e-05\n",
      "Epoch 154/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3256 - accuracy: 0.8986 - val_loss: 0.0563 - val_accuracy: 0.9830 - lr: 1.5625e-05\n",
      "Epoch 155/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3249 - accuracy: 0.8990 - val_loss: 0.0559 - val_accuracy: 0.9830 - lr: 1.5625e-05\n",
      "Epoch 156/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3277 - accuracy: 0.8986 - val_loss: 0.0559 - val_accuracy: 0.9833 - lr: 1.5625e-05\n",
      "Epoch 157/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3232 - accuracy: 0.9002 - val_loss: 0.0570 - val_accuracy: 0.9827 - lr: 1.5625e-05\n",
      "Epoch 158/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3251 - accuracy: 0.8986 - val_loss: 0.0557 - val_accuracy: 0.9828 - lr: 1.5625e-05\n",
      "Epoch 159/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3222 - accuracy: 0.9002 - val_loss: 0.0562 - val_accuracy: 0.9831 - lr: 1.5625e-05\n",
      "Epoch 160/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3229 - accuracy: 0.8980 - val_loss: 0.0585 - val_accuracy: 0.9823 - lr: 1.5625e-05\n",
      "Epoch 161/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3342 - accuracy: 0.8963 - val_loss: 0.0565 - val_accuracy: 0.9832 - lr: 1.5625e-05\n",
      "Epoch 162/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3222 - accuracy: 0.9004 - val_loss: 0.0574 - val_accuracy: 0.9829 - lr: 1.5625e-05\n",
      "Epoch 163/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3258 - accuracy: 0.8980 - val_loss: 0.0573 - val_accuracy: 0.9829 - lr: 1.5625e-05\n",
      "Epoch 164/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3261 - accuracy: 0.8985 - val_loss: 0.0573 - val_accuracy: 0.9825 - lr: 1.5625e-05\n",
      "Epoch 165/300\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3281 - accuracy: 0.8984 - val_loss: 0.0569 - val_accuracy: 0.9829 - lr: 1.5625e-05\n",
      "Epoch 166/300\n",
      "935/937 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8989\n",
      "Epoch 166: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3232 - accuracy: 0.8990 - val_loss: 0.0561 - val_accuracy: 0.9827 - lr: 1.5625e-05\n",
      "Epoch 167/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3194 - accuracy: 0.9012 - val_loss: 0.0570 - val_accuracy: 0.9827 - lr: 7.8125e-06\n",
      "Epoch 168/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3211 - accuracy: 0.8997 - val_loss: 0.0560 - val_accuracy: 0.9829 - lr: 7.8125e-06\n",
      "Epoch 169/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3220 - accuracy: 0.9015 - val_loss: 0.0564 - val_accuracy: 0.9830 - lr: 7.8125e-06\n",
      "Epoch 170/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3237 - accuracy: 0.8998 - val_loss: 0.0572 - val_accuracy: 0.9829 - lr: 7.8125e-06\n",
      "Epoch 171/300\n",
      "937/937 [==============================] - 24s 26ms/step - loss: 0.3197 - accuracy: 0.9011 - val_loss: 0.0561 - val_accuracy: 0.9831 - lr: 7.8125e-06\n",
      "Epoch 172/300\n",
      "937/937 [==============================] - 25s 27ms/step - loss: 0.3248 - accuracy: 0.8999 - val_loss: 0.0566 - val_accuracy: 0.9829 - lr: 7.8125e-06\n",
      "Epoch 173/300\n",
      "935/937 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8990Restoring model weights from the end of the best epoch: 158.\n",
      "937/937 [==============================] - 25s 26ms/step - loss: 0.3249 - accuracy: 0.8990 - val_loss: 0.0557 - val_accuracy: 0.9830 - lr: 7.8125e-06\n",
      "Epoch 173: early stopping\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0557 - accuracy: 0.9828\n",
      "Test accuracy: 0.9828000068664551\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    "    Flatten,\n",
    ")\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据预处理\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)  # 增加通道维度\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 数据增强\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    zoom_range=0.5,\n",
    "    shear_range=0.5,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 构建多层感知机（MLP）神经网络模型\n",
    "model = Sequential(\n",
    "    [\n",
    "        Flatten(input_shape=(28, 28, 1)),\n",
    "\n",
    "        Dense(1024), # Dense 全连接层\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(1024),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # ------- 做两层完全一样的 强化提取特征值 -------\n",
    "        \n",
    "        Dense(512),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(256),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(128),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(64),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(32),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        # ------------------ 输出 ------------------\n",
    "        Dense(10, activation=\"softmax\"),  # 输出层\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),  # 使用RMSprop优化器\n",
    "    loss=\"categorical_crossentropy\",  # 多分类交叉熵损失\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 回调函数\n",
    "# 在损失函数平稳时减小学习率\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "# 提前停止 达到最优值时停止训练\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=15, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=64),\n",
    "    epochs=300,\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // 64,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)  # 使用调整后的测试数据形状\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# 保存模型\n",
    "model.save(\"mnist_model_mlp_v1.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
