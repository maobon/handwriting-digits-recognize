{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e27b176-d698-4e04-8b27-78f53d0265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 16:17:04.283718: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-01-11 16:17:04.283746: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-01-11 16:17:04.283753: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-01-11 16:17:04.283790: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-11 16:17:04.283811: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 16:17:05.372256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - ETA: 0s - loss: 1.3660 - accuracy: 0.5603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 16:17:20.275898: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 18s 34ms/step - loss: 1.3660 - accuracy: 0.5603 - val_loss: 0.2517 - val_accuracy: 0.9338 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.5328 - accuracy: 0.8513 - val_loss: 0.1630 - val_accuracy: 0.9515 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.3997 - accuracy: 0.8920 - val_loss: 0.1230 - val_accuracy: 0.9649 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.3354 - accuracy: 0.9089 - val_loss: 0.1057 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.2968 - accuracy: 0.9206 - val_loss: 0.0890 - val_accuracy: 0.9730 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.2725 - accuracy: 0.9268 - val_loss: 0.0761 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.2575 - accuracy: 0.9312 - val_loss: 0.0785 - val_accuracy: 0.9772 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.2400 - accuracy: 0.9354 - val_loss: 0.0726 - val_accuracy: 0.9794 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.2283 - accuracy: 0.9390 - val_loss: 0.0634 - val_accuracy: 0.9816 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.2131 - accuracy: 0.9415 - val_loss: 0.0785 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.2051 - accuracy: 0.9442 - val_loss: 0.0754 - val_accuracy: 0.9773 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.2011 - accuracy: 0.9453 - val_loss: 0.0610 - val_accuracy: 0.9828 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1940 - accuracy: 0.9468 - val_loss: 0.0567 - val_accuracy: 0.9838 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1851 - accuracy: 0.9500 - val_loss: 0.0525 - val_accuracy: 0.9855 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1817 - accuracy: 0.9511 - val_loss: 0.0528 - val_accuracy: 0.9848 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1750 - accuracy: 0.9531 - val_loss: 0.0533 - val_accuracy: 0.9845 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1743 - accuracy: 0.9523 - val_loss: 0.0532 - val_accuracy: 0.9836 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1677 - accuracy: 0.9536 - val_loss: 0.0461 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1634 - accuracy: 0.9547 - val_loss: 0.0577 - val_accuracy: 0.9818 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1610 - accuracy: 0.9562 - val_loss: 0.0465 - val_accuracy: 0.9866 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1593 - accuracy: 0.9567 - val_loss: 0.0472 - val_accuracy: 0.9855 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1587 - accuracy: 0.9568 - val_loss: 0.0474 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1501 - accuracy: 0.9590 - val_loss: 0.0404 - val_accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1450 - accuracy: 0.9601 - val_loss: 0.0433 - val_accuracy: 0.9869 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1443 - accuracy: 0.9603 - val_loss: 0.0398 - val_accuracy: 0.9882 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "469/469 [==============================] - 16s 33ms/step - loss: 0.1414 - accuracy: 0.9615 - val_loss: 0.0430 - val_accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1436 - accuracy: 0.9608 - val_loss: 0.0429 - val_accuracy: 0.9875 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "469/469 [==============================] - 15s 32ms/step - loss: 0.1437 - accuracy: 0.9608 - val_loss: 0.0429 - val_accuracy: 0.9871 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1387 - accuracy: 0.9619 - val_loss: 0.0381 - val_accuracy: 0.9882 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "469/469 [==============================] - 15s 33ms/step - loss: 0.1335 - accuracy: 0.9635 - val_loss: 0.0450 - val_accuracy: 0.9861 - lr: 0.0010\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0450 - accuracy: 0.9861\n",
      "Test accuracy: 0.9861000180244446\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Input,\n",
    "    LeakyReLU,\n",
    ")\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据预处理：归一化\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)  # 调整形状以匹配模型输入\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 数据增强\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "datagen.fit(x_train.reshape(-1, 28, 28, 1))  # 数据增强需要原始形状\n",
    "\n",
    "# 构建多层感知机（MLP）神经网络模型\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(28, 28, 1)),  # 输入层\n",
    "        \n",
    "        tf.keras.layers.Flatten(),  # 展平图像\n",
    "        Dense(2048),  # 隐藏层 1\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(1024),  # 隐藏层 2\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(512),  # 隐藏层 3\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(256),  # 隐藏层 4\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(128),  # 隐藏层 5\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(64),  # 隐藏层 6\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(32),  # 隐藏层 7\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(10, activation=\"softmax\"),  # 输出层\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),  # 使用RMSprop优化器\n",
    "    loss=\"categorical_crossentropy\",  # 多分类交叉熵损失\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 回调函数\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=8, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    datagen.flow(x_train.reshape(-1, 28, 28, 1), y_train, batch_size=128),  # 调整批量大小并恢复原始形状\n",
    "    epochs=30,  # 增加训练轮数\n",
    "    validation_data=(x_test.reshape(-1, 28, 28, 1), y_test),  # 恢复原始形状\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)  # 使用调整后的测试数据形状\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# 保存模型\n",
    "model.save(\"mnist_model_mlp_v1.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
