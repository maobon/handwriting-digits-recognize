{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e27b176-d698-4e04-8b27-78f53d0265b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinbob/PycharmProjects/tensorflow-sample/env/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-01-09 17:29:38.853926: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-01-09 17:29:38.853958: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-01-09 17:29:38.853962: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-01-09 17:29:38.853980: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-09 17:29:38.853993: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinbob/PycharmProjects/tensorflow-sample/env/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2025-01-09 17:29:40.391006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 50ms/step - accuracy: 0.1780 - loss: 2.6269 - val_accuracy: 0.8631 - val_loss: 0.5765 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 54ms/step - accuracy: 0.2969 - loss: 1.7254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinbob/PycharmProjects/tensorflow-sample/env/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2969 - loss: 1.7254 - val_accuracy: 0.8557 - val_loss: 0.5999 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 46ms/step - accuracy: 0.5130 - loss: 1.4108 - val_accuracy: 0.9346 - val_loss: 0.2069 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6406 - loss: 1.0887 - val_accuracy: 0.9347 - val_loss: 0.2096 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 46ms/step - accuracy: 0.6378 - loss: 1.0683 - val_accuracy: 0.9527 - val_loss: 0.1561 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6250 - loss: 1.4256 - val_accuracy: 0.9540 - val_loss: 0.1530 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.6890 - loss: 0.9315 - val_accuracy: 0.9673 - val_loss: 0.1048 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.7434 - val_accuracy: 0.9676 - val_loss: 0.1049 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.7059 - loss: 0.8725 - val_accuracy: 0.9507 - val_loss: 0.1663 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6562 - loss: 0.8580 - val_accuracy: 0.9523 - val_loss: 0.1615 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.7223 - loss: 0.8253 - val_accuracy: 0.9655 - val_loss: 0.1163 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.8183 - val_accuracy: 0.9657 - val_loss: 0.1160 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7358 - loss: 0.7886 - val_accuracy: 0.9671 - val_loss: 0.1067 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.4984 - val_accuracy: 0.9670 - val_loss: 0.1083 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7444 - loss: 0.7623\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7444 - loss: 0.7623 - val_accuracy: 0.9650 - val_loss: 0.1155 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.7032 - val_accuracy: 0.9648 - val_loss: 0.1160 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7623 - loss: 0.7115 - val_accuracy: 0.9679 - val_loss: 0.1045 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.6650 - val_accuracy: 0.9681 - val_loss: 0.1036 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7618 - loss: 0.7055 - val_accuracy: 0.9761 - val_loss: 0.0733 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.8405 - val_accuracy: 0.9761 - val_loss: 0.0733 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7674 - loss: 0.6932 - val_accuracy: 0.9715 - val_loss: 0.0937 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.6540 - val_accuracy: 0.9717 - val_loss: 0.0936 - learning_rate: 5.0000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7725 - loss: 0.6803 - val_accuracy: 0.9681 - val_loss: 0.1040 - learning_rate: 5.0000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.5882 - val_accuracy: 0.9682 - val_loss: 0.1028 - learning_rate: 5.0000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7772 - loss: 0.6668 - val_accuracy: 0.9751 - val_loss: 0.0818 - learning_rate: 5.0000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.7248 - val_accuracy: 0.9752 - val_loss: 0.0825 - learning_rate: 5.0000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7749 - loss: 0.6727\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7749 - loss: 0.6727 - val_accuracy: 0.9733 - val_loss: 0.0823 - learning_rate: 5.0000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.7620 - val_accuracy: 0.9736 - val_loss: 0.0815 - learning_rate: 2.5000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7817 - loss: 0.6488 - val_accuracy: 0.9739 - val_loss: 0.0818 - learning_rate: 2.5000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.5141 - val_accuracy: 0.9743 - val_loss: 0.0817 - learning_rate: 2.5000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7872 - loss: 0.6353 - val_accuracy: 0.9758 - val_loss: 0.0754 - learning_rate: 2.5000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.7368 - val_accuracy: 0.9758 - val_loss: 0.0753 - learning_rate: 2.5000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7889 - loss: 0.6323 - val_accuracy: 0.9756 - val_loss: 0.0762 - learning_rate: 2.5000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.4872 - val_accuracy: 0.9756 - val_loss: 0.0765 - learning_rate: 2.5000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7901 - loss: 0.6285\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7901 - loss: 0.6285 - val_accuracy: 0.9754 - val_loss: 0.0810 - learning_rate: 2.5000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.6882 - val_accuracy: 0.9753 - val_loss: 0.0812 - learning_rate: 1.2500e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7919 - loss: 0.6239 - val_accuracy: 0.9780 - val_loss: 0.0719 - learning_rate: 1.2500e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.8582 - val_accuracy: 0.9781 - val_loss: 0.0717 - learning_rate: 1.2500e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7949 - loss: 0.6092 - val_accuracy: 0.9749 - val_loss: 0.0809 - learning_rate: 1.2500e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.4350 - val_accuracy: 0.9749 - val_loss: 0.0809 - learning_rate: 1.2500e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 70ms/step - accuracy: 0.7944 - loss: 0.6130 - val_accuracy: 0.9774 - val_loss: 0.0728 - learning_rate: 1.2500e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 139ms/step - accuracy: 0.6562 - loss: 0.8359 - val_accuracy: 0.9775 - val_loss: 0.0726 - learning_rate: 1.2500e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7945 - loss: 0.6127 - val_accuracy: 0.9760 - val_loss: 0.0768 - learning_rate: 1.2500e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.5317 - val_accuracy: 0.9758 - val_loss: 0.0772 - learning_rate: 1.2500e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7957 - loss: 0.6073 - val_accuracy: 0.9764 - val_loss: 0.0750 - learning_rate: 1.2500e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 56ms/step - accuracy: 0.8125 - loss: 0.5153\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.5153 - val_accuracy: 0.9766 - val_loss: 0.0746 - learning_rate: 1.2500e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7993 - loss: 0.6009 - val_accuracy: 0.9744 - val_loss: 0.0781 - learning_rate: 6.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.8541 - val_accuracy: 0.9744 - val_loss: 0.0779 - learning_rate: 6.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.8034 - loss: 0.5916 - val_accuracy: 0.9746 - val_loss: 0.0807 - learning_rate: 6.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.7564 - val_accuracy: 0.9746 - val_loss: 0.0807 - learning_rate: 6.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.8014 - loss: 0.5899 - val_accuracy: 0.9739 - val_loss: 0.0809 - learning_rate: 6.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.6375 - val_accuracy: 0.9740 - val_loss: 0.0807 - learning_rate: 6.2500e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7982 - loss: 0.6037 - val_accuracy: 0.9766 - val_loss: 0.0735 - learning_rate: 6.2500e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 48ms/step - accuracy: 0.8125 - loss: 0.7217\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.7217 - val_accuracy: 0.9766 - val_loss: 0.0733 - learning_rate: 6.2500e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7989 - loss: 0.5983 - val_accuracy: 0.9759 - val_loss: 0.0770 - learning_rate: 3.1250e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7656 - loss: 0.7920 - val_accuracy: 0.9759 - val_loss: 0.0772 - learning_rate: 3.1250e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.7990 - loss: 0.6041 - val_accuracy: 0.9753 - val_loss: 0.0780 - learning_rate: 3.1250e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.5990 - val_accuracy: 0.9750 - val_loss: 0.0781 - learning_rate: 3.1250e-05\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.0882\n",
      "Test accuracy: 0.9781000018119812\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# 加载MNIST数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 数据预处理\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)  # 增加通道维度\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# 数据增强\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.5,\n",
    "    height_shift_range=0.5,\n",
    "    zoom_range=0.5,\n",
    "    shear_range=0.5,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 回调函数\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=8, min_lr=1e-6, verbose=1\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=20, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# 构建改进的CNN模型\n",
    "# 卷积神经网络\n",
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1), padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.4),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=64),\n",
    "    epochs=200,\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // 64,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    ")\n",
    "\n",
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# 保存模型\n",
    "model.save(\"mnist_model_optimized_v10.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
